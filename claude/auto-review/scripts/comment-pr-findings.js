#!/usr/bin/env node

/**
 * Comment on PRs with inline findings generated by the Claude auto-review action.
 *
 * Behaviour is intentionally aligned with anthropics/claude-code-security-review/scripts/comment-pr-findings.js
 * so that any upstream improvements can be ported with minimal friction.
 */

import fs from "fs";
import path from "path";
import crypto from "crypto";
import { ghApi, loadGitHubContext } from "./lib/github-utils.js";

// ---- Utility helpers -----------------------------------------------------

/**
 * Parse diff patch to extract valid line ranges for the RIGHT side (new file)
 * @param {string} patch - The patch/diff string from GitHub API
 * @returns {Array<{start: number, end: number}>} Array of valid line ranges
 */
export function parseDiffHunks(patch) {
  if (!patch) return [];

  const ranges = [];
  // Match hunk headers like @@ -10,6 +13,8 @@ or @@ -0,0 +1,5 @@
  const hunkPattern = /@@ -\d+(?:,\d+)? \+(\d+)(?:,(\d+))? @@/g;

  let match;
  while ((match = hunkPattern.exec(patch)) !== null) {
    const startLine = parseInt(match[1], 10);
    const lineCount = match[2] ? parseInt(match[2], 10) : 1;
    ranges.push({
      start: startLine,
      end: startLine + lineCount - 1
    });
  }

  return ranges;
}

/**
 * Check if a line number is within any of the diff hunk ranges
 * @param {number} line - Line number to check
 * @param {Array<{start: number, end: number}>} ranges - Array of valid ranges
 * @returns {boolean} True if line is within a hunk
 */
export function isLineInDiff(line, ranges) {
  return ranges.some(range => line >= range.start && line <= range.end);
}

/**
 * Read and parse a JSON file
 * @param {string} filePath - Path to JSON file
 * @returns {Object|null} Parsed JSON data or null if file doesn't exist
 */
export function readJsonFile(filePath) {
  try {
    const data = fs.readFileSync(filePath, "utf8");
    return JSON.parse(data);
  } catch (error) {
    if (error.code === "ENOENT") {
      console.log(
        `Findings file not found at ${filePath}, skipping PR commenting.`
      );
      return null;
    }
    console.error(
      `Failed to read findings file at ${filePath}: ${error.message}`
    );
    throw error;
  }
}

/**
 * Generate a stable hash for finding deduplication
 * @param {string} file - File path
 * @param {string} description - Finding description
 * @param {string|null} claudeId - Claude-generated semantic ID (preferred)
 * @returns {string} Finding hash/ID
 */
export function generateFindingHash(file, description, claudeId = null) {
  // Prefer Claude's ID if available (already semantic and stable)
  if (claudeId && claudeId.length > 0) {
    return claudeId;
  }

  // Fallback to hash for backward compatibility
  const content = `${file}::${description}`;
  return crypto
    .createHash("sha256")
    .update(content)
    .digest("hex")
    .substring(0, 16);
}

// ---- Main execution ------------------------------------------------------

/**
 * Main entry point for the script
 */
export function main() {
  const silence = process.env.SILENCE_AUTO_REVIEW_COMMENTS === "true";
  if (silence) {
    console.log(
      "Auto-review comments silenced via SILENCE_AUTO_REVIEW_COMMENTS=true."
    );
    return;
  }

  const findingsPath = path.resolve(
    process.cwd(),
    process.env.FINDINGS_FILE || "findings.json"
  );
  const findings = readJsonFile(findingsPath);

  if (!findings || findings.length === 0) {
    console.log("No findings to report, exiting without commenting.");
    return;
  }

  const context = loadGitHubContext();
  if (!context.issue.number) {
    console.log(
      "GitHub event is not a pull request, skipping PR commenting step."
    );
    return;
  }

  const repoFiles =
    ghApi(
      `/repos/${context.repo.owner}/${context.repo.repo}/pulls/${context.issue.number}/files?per_page=100`
    ) || [];

  // Build file map with parsed diff hunk ranges
  const fileMap = repoFiles.reduce((acc, file) => {
    acc[file.filename] = {
      ...file,
      diffRanges: parseDiffHunks(file.patch)
    };
    return acc;
  }, {});

  const reviewComments = [];

  for (const finding of findings) {
    const file = finding.file || finding.path;
    const line = finding.line || (finding.start && finding.start.line) || 1;
    if (!file || !fileMap[file]) {
      console.log(
        `Finding references file ${file} which is not present in PR diff; skipping.`
      );
      continue;
    }

    // Check if line is within a diff hunk (GitHub API only allows comments on lines in the diff)
    const fileData = fileMap[file];
    if (!isLineInDiff(line, fileData.diffRanges)) {
      console.log(
        `Finding references ${file}:${line} which is outside diff hunks; skipping. Valid ranges: ${JSON.stringify(fileData.diffRanges)}`
      );
      continue;
    }

    const message =
      finding.description ||
      (finding.extra && finding.extra.message) ||
      "Issue detected by Claude Auto Review";
    const severity = finding.severity || "MEDIUM";
    const category = finding.category || "code_issue";

    // Generate hash for duplicate detection (prefer Claude's ID if available)
    const claudeId = finding.id || null;
    const findingHash = generateFindingHash(file, message, claudeId);

    let body = `<!-- finding-id: ${findingHash} -->\n`;
    body += `ðŸ¤– **Auto Review Issue: ${message}**\n\n`;
    body += `**Severity:** ${severity}\n`;
    body += `**Category:** ${category}\n`;
    body += `**Tool:** Claude Auto Review\n`;

    const exploit =
      finding.exploit_scenario ||
      (finding.extra &&
        finding.extra.metadata &&
        finding.extra.metadata.exploit_scenario);
    if (exploit) {
      body += `\n**Exploit Scenario:** ${exploit}\n`;
    }

    const recommendation =
      finding.recommendation ||
      (finding.extra &&
        finding.extra.metadata &&
        finding.extra.metadata.recommendation);
    if (recommendation) {
      body += `\n**Recommendation:** ${recommendation}\n`;
    }

    reviewComments.push({
      path: file,
      line,
      side: "RIGHT",
      body,
    });
  }

  if (reviewComments.length === 0) {
    console.log(
      "No valid findings to comment on (filtered out-of-diff items)."
    );
    return;
  }

  const existingComments =
    ghApi(
      `/repos/${context.repo.owner}/${context.repo.repo}/pulls/${context.issue.number}/comments`
    ) || [];

  // Extract finding IDs from existing bot comments
  // Fixed regex to match semantic IDs with hyphens (e.g., "users-sql-injection-f3a2")
  const existingFindingIds = new Set();
  existingComments.forEach((comment) => {
    if (comment.user?.type === "Bot" && comment.body) {
      const match = comment.body.match(/<!-- finding-id: ([a-z0-9\-]+) -->/);
      if (match) {
        existingFindingIds.add(match[1]);
      }
    }
  });

  console.log(
    `Found ${existingFindingIds.size} existing auto-review findings on this PR.`
  );

  // Filter out findings that already have comments
  const newReviewComments = reviewComments.filter((comment) => {
    const match = comment.body.match(/<!-- finding-id: ([a-z0-9\-]+) -->/);
    if (match && existingFindingIds.has(match[1])) {
      console.log(`Skipping duplicate finding: ${match[1]}`);
      return false;
    }
    return true;
  });

  if (newReviewComments.length === 0) {
    console.log("No new findings to comment on (all are duplicates).");
    return;
  }

  console.log(
    `Posting ${newReviewComments.length} new findings (${
      reviewComments.length - newReviewComments.length
    } duplicates skipped).`
  );

  // Get commit ID - for issue_comment events we need to fetch PR data
  let commitId = context.payload.pull_request?.head?.sha || null;
  if (!commitId) {
    // Fetch PR data to get head SHA (needed for issue_comment events)
    const prData = ghApi(
      `/repos/${context.repo.owner}/${context.repo.repo}/pulls/${context.issue.number}`
    );
    commitId = prData?.head?.sha || null;
    if (commitId) {
      console.log(`Fetched commit ID from PR data: ${commitId}`);
    }
  }

  if (!commitId) {
    console.error("Unable to determine commit ID for PR review comments.");
    return;
  }

  try {
    const reviewResponse = ghApi(
      `/repos/${context.repo.owner}/${context.repo.repo}/pulls/${context.issue.number}/reviews`,
      "POST",
      {
        commit_id: commitId,
        event: "COMMENT",
        comments: newReviewComments,
      }
    );

    if (reviewResponse?.id) {
      console.log(
        `Created review with ${newReviewComments.length} inline comments.`
      );
    }
  } catch (error) {
    console.error(
      `Failed to create review with inline comments: ${error.message}`
    );
    console.error(
      "Review request debug details:",
      JSON.stringify(
        {
          repo: context.repo,
          issueNumber: context.issue.number,
          commitId,
          findings: newReviewComments.length,
          firstFinding: newReviewComments[0],
          envGitHubSha: process.env.GITHUB_SHA || null,
          ghEndpoint: `/repos/${context.repo.owner}/${context.repo.repo}/pulls/${context.issue.number}/reviews`,
        },
        null,
        2
      )
    );
    if (error.stack) {
      console.error(error.stack);
    }
  }
}

// Execute main() only when run directly (not when imported for testing)
if (import.meta.url === `file://${process.argv[1]}`) {
  main();
}
